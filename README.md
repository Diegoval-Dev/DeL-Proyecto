# ğŸ¯ ActionMiner Lite - DetecciÃ³n de Tareas con NLP

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.36+-red.svg)](https://streamlit.io)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Sistema de procesamiento de lenguaje natural para detectar tareas en documentos en espaÃ±ol.**

---

## ğŸŒŸ CaracterÃ­sticas

- âœ… **ClasificaciÃ³n de Tareas**: Detecta oraciones que contienen tareas con F1=0.9863
- ğŸ‘¤ **ExtracciÃ³n de Responsables**: Identifica personas usando NER en espaÃ±ol
- ğŸ“… **NormalizaciÃ³n de Fechas**: Convierte fechas absolutas y relativas a formato ISO
- ğŸ¨ **Interfaz Web**: AplicaciÃ³n Streamlit profesional y fÃ¡cil de usar
- ğŸ“Š **ExportaciÃ³n CSV**: Descarga resultados en formato estructurado
- ğŸ“„ **Soporte PDF/TXT**: Procesa mÃºltiples formatos de entrada

## ğŸš€ Inicio RÃ¡pido

### InstalaciÃ³n

```bash
# Clonar el repositorio
git clone [tu-repo]
cd DeL-Proyecto

# Instalar dependencias
pip install -r requirements.txt
```

### Uso

#### OpciÃ³n 1: Script de Lanzamiento (Recomendado)

```bash
./run_app.sh
```

#### OpciÃ³n 2: Comando Directo

```bash
streamlit run app/streamlit_app.py
```

#### OpciÃ³n 3: Verificar Pipeline

```bash
python test_pipeline.py
```

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en tu navegador en `http://localhost:8501`

## ğŸ“– Ejemplo de Uso

### Entrada

```text
Juan debe enviar el informe antes del viernes 15 de noviembre.
Se discutiÃ³ el presupuesto del proyecto.
MarÃ­a coordinarÃ¡ la reuniÃ³n con el equipo tÃ©cnico el prÃ³ximo martes.
```

### Salida (CSV)

| sent_id | oracion | es_tarea | score | responsable | fecha_iso |
|---------|---------|----------|-------|-------------|-----------|
| 0 | Juan debe enviar el informe... | TRUE | 0.989 | Juan | 2025-11-15 |
| 1 | Se discutiÃ³ el presupuesto... | FALSE | 0.024 | - | - |
| 2 | MarÃ­a coordinarÃ¡ la reuniÃ³n... | TRUE | 0.979 | MarÃ­a | 2025-11-12 |

## ğŸ—ï¸ Arquitectura

```
ğŸ“„ Entrada (PDF/TXT/Texto)
    â†“
ğŸ§¹ Preprocesamiento
    â†“
âœ‚ï¸ SegmentaciÃ³n en Oraciones
    â†“
ğŸ¤– ClasificaciÃ³n (Embeddings + LogReg)
    â†“
SI es TAREA â†’
    ğŸ‘¤ NER (Responsable)
    ğŸ“… ExtracciÃ³n de Fecha
    â†“
ğŸ’¾ ExportaciÃ³n CSV
```

## ğŸ“Š Rendimiento del Modelo

### MÃ©tricas en Test Set

| MÃ©trica | Valor |
|---------|-------|
| **F1 Score** | 0.9863 |
| **Precision** | 0.9744 |
| **Recall** | 1.0000 |
| **Accuracy** | 0.9867 |

### Dataset

- **Total**: 500 oraciones etiquetadas
- **Balance**: 53% TAREA / 47% NO_TAREA
- **Splits**: 70% train / 15% dev / 15% test

### Modelos Entrenados

| Experimento | Modelo | F1 (dev) | Estado |
|-------------|--------|----------|--------|
| Embeddings + LogReg | Spanish Embeddings | 1.0000 | âœ… Mejor |
| BERT Fine-tuning | Multilingual BERT | 1.0000 | âœ… |
| Ensemble | Soft Voting | 1.0000 | âœ… |

## ğŸ“ Estructura del Proyecto

```
DeL-Proyecto/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py          # AplicaciÃ³n web principal
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py             # Limpieza de texto
â”‚   â”œâ”€â”€ sentence_split.py         # SegmentaciÃ³n
â”‚   â”œâ”€â”€ infer_classifier.py       # ClasificaciÃ³n
â”‚   â”œâ”€â”€ ner_extract.py            # ExtracciÃ³n de responsables
â”‚   â”œâ”€â”€ date_extract.py           # ExtracciÃ³n de fechas
â”‚   â””â”€â”€ experiments/              # Scripts de experimentaciÃ³n
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ annotations/              # Dataset etiquetado (500 oraciones)
â”‚   â””â”€â”€ splits/                   # Train/dev/test
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_baseline/            # Mejor modelo (F1=0.9863)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ unit/                     # 17 tests unitarios
â”œâ”€â”€ eval/                         # Resultados y visualizaciones
â”œâ”€â”€ INSTRUCCIONES_USO.md          # GuÃ­a detallada de usuario
â”œâ”€â”€ RESUMEN_PROYECTO.md           # Resumen ejecutivo completo
â””â”€â”€ test_pipeline.py              # Script de verificaciÃ³n
```

## ğŸ§ª Testing

Ejecutar tests unitarios:

```bash
pytest tests/unit/ -v
```

Verificar pipeline completo:

```bash
python test_pipeline.py
```

## ğŸ“š DocumentaciÃ³n

- **[INSTRUCCIONES_USO.md](INSTRUCCIONES_USO.md)**: GuÃ­a completa de usuario
- **[RESUMEN_PROYECTO.md](RESUMEN_PROYECTO.md)**: Resumen ejecutivo y resultados
- **[CLAUDE.md](CLAUDE.md)**: Especificaciones tÃ©cnicas detalladas

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.10+**: Lenguaje principal
- **Transformers (Hugging Face)**: Modelos BERT y NER
- **Sentence-Transformers**: Embeddings de oraciones
- **Scikit-learn**: ClasificaciÃ³n y grid search
- **Streamlit**: Interfaz web
- **dateparser**: NormalizaciÃ³n de fechas
- **pdfplumber**: ExtracciÃ³n de texto de PDFs
- **pytest**: Testing

## ğŸ“ Casos de Uso

### 1. AnÃ¡lisis de Actas de ReuniÃ³n

Extrae automÃ¡ticamente:
- Tareas asignadas a cada persona
- Fechas lÃ­mite de entrega
- Compromisos adquiridos

### 2. GestiÃ³n de Emails Corporativos

Identifica:
- Solicitudes de acciÃ³n
- Responsables de seguimiento
- Plazos de respuesta

### 3. Procesamiento de Documentos Legales/Administrativos

Detecta:
- Obligaciones contractuales
- Fechas de vencimiento
- Partes responsables

## ğŸ” Funcionalidades Avanzadas

### ClasificaciÃ³n Inteligente

- Modelo entrenado con 500 oraciones reales
- Grid search con 16 combinaciones de hiperparÃ¡metros
- CalibraciÃ³n de umbral por F1 score

### ExtracciÃ³n de Responsables

- NER BERT fine-tuned en espaÃ±ol
- VinculaciÃ³n contextual con verbos de acciÃ³n
- DetecciÃ³n de proximidad responsable-verbo

### NormalizaciÃ³n de Fechas

- Fechas absolutas: "15/11/2025", "15 de noviembre de 2025"
- Fechas relativas: "maÃ±ana", "prÃ³ximo martes", "esta semana"
- Salida en formato ISO (YYYY-MM-DD)

## ğŸš§ Limitaciones Conocidas

- â— Solo procesa documentos con texto embebido (no OCR)
- â— Optimizado para espaÃ±ol de EspaÃ±a/LatinoamÃ©rica
- â— NER puede fallar con nombres poco comunes
- â— Fechas ambiguas dependen de la fecha base configurada

## ğŸ¤ Contribuciones

Para reportar bugs o sugerir mejoras:

1. Revisar documentaciÃ³n existente
2. Ejecutar `test_pipeline.py` para reproducir
3. Incluir ejemplos especÃ­ficos del problema

## ğŸ“ Changelog

### v1.0.0 (Noviembre 2025)

- âœ… Sistema completo funcional
- âœ… 3 experimentos de ML completados
- âœ… Interfaz Streamlit profesional
- âœ… 17 tests unitarios pasando
- âœ… F1 = 0.9863 en test set
- âœ… DocumentaciÃ³n completa

## ğŸ“„ Licencia

Este proyecto fue desarrollado como parte del curso de Deep Learning en la Universidad del Valle de Guatemala.

## ğŸ‘¥ Autores

**Proyecto**: ActionMiner Lite
**Curso**: Deep Learning y Sistemas Inteligentes
**InstituciÃ³n**: Universidad del Valle de Guatemala
**AÃ±o**: 2025

---

## ğŸƒ Comandos RÃ¡pidos

```bash
# Instalar
pip install -r requirements.txt

# Ejecutar app
./run_app.sh
# o
streamlit run app/streamlit_app.py

# Probar pipeline
python test_pipeline.py

# Tests
pytest tests/unit/ -v

# Experimentos
python src/experiments/exp01_embeddings_logreg.py
python src/experiments/compare_all.py
```

---

**Estado**: âœ… Completado y Funcional

**Ãšltima actualizaciÃ³n**: Noviembre 2025

Para mÃ¡s informaciÃ³n, consulta [INSTRUCCIONES_USO.md](INSTRUCCIONES_USO.md) o [RESUMEN_PROYECTO.md](RESUMEN_PROYECTO.md)
