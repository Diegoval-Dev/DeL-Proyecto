# üèóÔ∏è Arquitectura del Proyecto - ActionMiner Lite

**Versi√≥n**: 1.0.0
**Fecha de Baseline**: 2025-11-09
**Estado**: Producci√≥n

---

## üìã Tabla de Contenidos

1. [Baseline del Proyecto](#baseline-del-proyecto)
2. [Arquitectura General](#arquitectura-general)
3. [Estructura de Carpetas](#estructura-de-carpetas)
4. [Componentes Principales](#componentes-principales)
5. [Pipeline de Procesamiento](#pipeline-de-procesamiento)
6. [Convenciones de Organizaci√≥n](#convenciones-de-organizaci√≥n)
7. [Cambios Realizados en esta Limpieza](#cambios-realizados-en-esta-limpieza)

---

## Baseline del Proyecto

### Estado Estable

Este baseline representa la versi√≥n **1.0.0** de ActionMiner Lite despu√©s de:

1. ‚úÖ Generaci√≥n de 29 variantes LLM para aumentaci√≥n de datos
2. ‚úÖ Re-entrenamiento del modelo con dataset mejorado (589 oraciones)
3. ‚úÖ Implementaci√≥n de 5 estrategias LLM-asistidas
4. ‚úÖ Limpieza y organizaci√≥n completa del repositorio

### M√©tricas del Baseline

```
Clasificaci√≥n:
  - F1 Score (test):      0.926
  - Precision:            0.90
  - Recall:               0.96
  - Dataset:              589 oraciones

Extracci√≥n:
  - Responsable EM:       0.455 (+14% vs v0.1)
  - Fecha EM:             0.316 (+187% vs v0.1)

Performance:
  - Latencia:             ~12ms/oraci√≥n
  - Throughput:           ~80 oraciones/seg
```

### Componentes Estables

- **Modelo de clasificaci√≥n**: `distiluse-base-multilingual-cased-v2` + LogReg
- **NER**: `mrm8488/bert-spanish-cased-finetuned-ner`
- **Parsing de fechas**: `dateparser` con reglas customizadas
- **App**: Streamlit con upload PDF/TXT y export CSV

---

## Arquitectura General

### Diagrama de Alto Nivel

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     ACTIONMINER LITE                        ‚îÇ
‚îÇ                  Sistema de Detecci√≥n de Tareas             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                             ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  Frontend   ‚îÇ              ‚îÇ  Processing ‚îÇ
         ‚îÇ  (Streamlit)‚îÇ              ‚îÇ  Pipeline   ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                             ‚îÇ
                ‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                      ‚îÇ             ‚îÇ
                ‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ               ‚îÇ Classifier  ‚îÇ ‚îÇExtract ‚îÇ
                ‚îÇ               ‚îÇ (F1 0.926)  ‚îÇ ‚îÇ(NER+RE)‚îÇ
                ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                      ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                          ‚îÇ
                                                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                   ‚îÇ   Output    ‚îÇ
                                                   ‚îÇ  (CSV/JSON) ‚îÇ
                                                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Stack Tecnol√≥gico

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CAPA                    ‚îÇ TECNOLOG√çAS                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Frontend                ‚îÇ Streamlit 1.x                     ‚îÇ
‚îÇ ML/NLP                  ‚îÇ sentence-transformers, sklearn    ‚îÇ
‚îÇ NER                     ‚îÇ transformers (BERT espa√±ol)       ‚îÇ
‚îÇ Parsing                 ‚îÇ dateparser, regex                 ‚îÇ
‚îÇ PDF                     ‚îÇ pdfplumber                        ‚îÇ
‚îÇ Testing                 ‚îÇ pytest                            ‚îÇ
‚îÇ LLM (opcional)          ‚îÇ anthropic (Claude)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Estructura de Carpetas

### √Årbol del Proyecto

```
DeL-Proyecto/
‚îÇ
‚îú‚îÄ‚îÄ app/                          # Aplicaci√≥n web
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py          # App principal Streamlit
‚îÇ
‚îú‚îÄ‚îÄ src/                          # C√≥digo fuente principal
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Core Processing:
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py             # Limpieza de texto
‚îÇ   ‚îú‚îÄ‚îÄ sentence_split.py         # Segmentaci√≥n en oraciones
‚îÇ   ‚îú‚îÄ‚îÄ featurize.py              # Generaci√≥n de embeddings
‚îÇ   ‚îú‚îÄ‚îÄ postprocess.py            # Normalizaci√≥n de outputs
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Classification:
‚îÇ   ‚îú‚îÄ‚îÄ train_classifier.py       # Entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ infer_classifier.py       # Inferencia (PRODUCCI√ìN)
‚îÇ   ‚îú‚îÄ‚îÄ infer_classifier_with_threshold.py  # Con umbral custom
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Extraction:
‚îÇ   ‚îú‚îÄ‚îÄ ner_extract.py            # Extracci√≥n de PERSON (responsable)
‚îÇ   ‚îú‚îÄ‚îÄ date_extract.py           # Extracci√≥n y normalizaci√≥n de fechas
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ IO:
‚îÇ   ‚îú‚îÄ‚îÄ io_pdf.py                 # Lectura de PDFs
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Evaluation:
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py               # Evaluaci√≥n en test set
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_baseline.py      # Evaluaci√≥n del baseline
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ experiments/              # Experimentos de ML
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exp01_embeddings_logreg.py     # Baseline (PRODUCCI√ìN)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exp02_bert_finetuning.py       # BERT fine-tuning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exp03_ensemble.py              # Ensemble
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ compare_all.py                 # Comparaci√≥n de modelos
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ analysis/                 # An√°lisis y debugging
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyze_real_errors.py         # An√°lisis de errores
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ error_analysis.py              # Error analysis general
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ llm_augmentation/         # Mejoras con LLM (opcional)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate_difficult_data.py     # Generaci√≥n de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ disambiguate_person.py         # Desambiguaci√≥n de PERSON
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normalize_dates.py             # Normalizaci√≥n de fechas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate_tests.py              # Generaci√≥n de tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enhanced_pipeline.py           # Pipeline con LLM
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md                      # Doc t√©cnica LLM
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ scripts/                  # Scripts de utilidades
‚îÇ       ‚îú‚îÄ‚îÄ integrate_llm_variants.py      # Integrar variantes LLM
‚îÇ       ‚îú‚îÄ‚îÄ integrate_tricky_negatives.py  # Integrar negativos
‚îÇ       ‚îî‚îÄ‚îÄ tune_threshold_improved.py     # Ajuste de umbral
‚îÇ
‚îú‚îÄ‚îÄ data/                         # Datos del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ annotations/              # Datos anotados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ all_annotations.jsonl          # Dataset completo (589)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tricky_negatives.jsonl         # Negativos dif√≠ciles
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_generated_variants.jsonl   # Variantes LLM (29)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ splits/                   # Train/dev/test
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.jsonl           # 408 oraciones
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dev.jsonl             # 86 oraciones
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test.jsonl            # 95 oraciones
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ scripts/                  # Scripts de datos
‚îÇ       ‚îú‚îÄ‚îÄ create_splits.py               # Crear splits
‚îÇ       ‚îú‚îÄ‚îÄ generate_tricky_negatives.py   # Generar negativos
‚îÇ       ‚îî‚îÄ‚îÄ merge_datasets.py              # Merge datasets
‚îÇ
‚îú‚îÄ‚îÄ models/                       # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ best_baseline/            # Modelo en producci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classifier.pkl                 # LogReg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ encoder.pkl                    # SentenceTransformer
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ threshold.txt                  # Umbral (0.65)
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ exp01_embeddings_logreg/  # Experimentos
‚îÇ
‚îú‚îÄ‚îÄ tests/                        # Tests automatizados
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ unit/                     # Unit tests
‚îÇ       ‚îú‚îÄ‚îÄ test_classifier.py
‚îÇ       ‚îú‚îÄ‚îÄ test_preprocess.py
‚îÇ       ‚îú‚îÄ‚îÄ test_sentence_split.py
‚îÇ       ‚îî‚îÄ‚îÄ test_date_extract.py
‚îÇ
‚îú‚îÄ‚îÄ scripts/                      # Scripts de utilidad
‚îÇ   ‚îú‚îÄ‚îÄ test_pipeline.py          # Test end-to-end
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_model.py         # Evaluaci√≥n r√°pida
‚îÇ   ‚îî‚îÄ‚îÄ test_document.txt         # Documento de prueba
‚îÇ
‚îú‚îÄ‚îÄ eval/                         # Resultados de evaluaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ test_results_v2.json      # Resultados actuales
‚îÇ   ‚îú‚îÄ‚îÄ threshold_tuning_improved.json
‚îÇ   ‚îî‚îÄ‚îÄ real_data_error_analysis.json
‚îÇ
‚îú‚îÄ‚îÄ docs/                         # Documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ CLAUDE.md                 # Plan t√©cnico original
‚îÇ   ‚îú‚îÄ‚îÄ INSTRUCCIONES_USO.md      # C√≥mo usar la app
‚îÇ   ‚îú‚îÄ‚îÄ PROYECTO_COMPLETADO.md    # Reporte final
‚îÇ   ‚îú‚îÄ‚îÄ MEJORAS_SOBREAJUSTE.md    # Correcci√≥n overfitting
‚îÇ   ‚îú‚îÄ‚îÄ ESTRATEGIAS_LLM_IMPLEMENTADAS.md
‚îÇ   ‚îú‚îÄ‚îÄ RESULTADOS_MEJORA.md
‚îÇ   ‚îú‚îÄ‚îÄ RESUMEN_MEJORAS_LLM.md
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ archive/                  # Docs antiguos
‚îÇ       ‚îú‚îÄ‚îÄ PROJECT.md
‚îÇ       ‚îú‚îÄ‚îÄ RESUMEN_PROYECTO.md
‚îÇ       ‚îî‚îÄ‚îÄ reports.md
‚îÇ
‚îú‚îÄ‚îÄ README.md                     # Documentaci√≥n principal
‚îú‚îÄ‚îÄ ARCHITECTURE.md               # Este archivo
‚îú‚îÄ‚îÄ requirements.txt              # Dependencias Python
‚îî‚îÄ‚îÄ run_app.sh                    # Script de inicio
```

---

## Componentes Principales

### 1. Core Processing (`src/`)

#### `preprocess.py`
- **Responsabilidad**: Limpieza de texto
- **Funciones**: `clean_text(text) -> str`
- **Transformaciones**: Normalizaci√≥n de espacios, eliminaci√≥n de footers

#### `sentence_split.py`
- **Responsabilidad**: Segmentaci√≥n en oraciones
- **Funciones**: `split_sentences(text) -> List[str]`
- **M√©todo**: Regex + reglas para espa√±ol

#### `featurize.py`
- **Responsabilidad**: Generaci√≥n de embeddings
- **Modelo**: `sentence-transformers/distiluse-base-multilingual-cased-v2`
- **Output**: Vectores de 512 dimensiones

### 2. Classification (`src/`)

#### `infer_classifier.py` ‚≠ê PRODUCCI√ìN
- **Responsabilidad**: Clasificaci√≥n TAREA/NO_TAREA
- **Clase**: `SentenceTaskClassifier`
- **M√©todo**: `predict_sentence(text) -> (bool, float)`
- **Modelo**: Embeddings + LogisticRegression
- **Umbral**: 0.65 (configurable en `models/best_baseline/threshold.txt`)

### 3. Extraction (`src/`)

#### `ner_extract.py`
- **Responsabilidad**: Extracci√≥n de responsable
- **Funci√≥n**: `extract_person_responsable(text) -> str`
- **Modelo**: `mrm8488/bert-spanish-cased-finetuned-ner`
- **Fallback**: "pendiente de asignar"

#### `date_extract.py`
- **Responsabilidad**: Extracci√≥n y normalizaci√≥n de fechas
- **Funci√≥n**: `extract_date_iso(text, base_date) -> str`
- **M√©todo**: Regex + dateparser
- **Output**: Formato ISO (YYYY-MM-DD)

### 4. App (`app/`)

#### `streamlit_app.py`
- **Responsabilidad**: Interfaz web
- **Features**:
  - Upload PDF/TXT
  - Procesamiento en tiempo real
  - Visualizaci√≥n de resultados
  - Export a CSV
- **URL**: http://localhost:8501 (por defecto)

---

## Pipeline de Procesamiento

### Flujo Completo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   INPUT     ‚îÇ  PDF, TXT o texto directo
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PDF Extract ‚îÇ  pdfplumber (si es PDF)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Preprocess  ‚îÇ  clean_text()
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Split     ‚îÇ  split_sentences()
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      PARA CADA ORACI√ìN           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  1. Featurize (embeddings) ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ           ‚îÇ                       ‚îÇ
‚îÇ           ‚ñº                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  2. Classify               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     (TAREA / NO_TAREA)     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ           ‚îÇ                       ‚îÇ
‚îÇ           ‚îú‚îÄ NO_TAREA ‚Üí Skip     ‚îÇ
‚îÇ           ‚îÇ                       ‚îÇ
‚îÇ           ‚îî‚îÄ TAREA ‚îÄ‚îê            ‚îÇ
‚îÇ                      ‚îÇ            ‚îÇ
‚îÇ           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ           ‚îÇ  3. Extract        ‚îÇ ‚îÇ
‚îÇ           ‚îÇ    - Responsable   ‚îÇ ‚îÇ
‚îÇ           ‚îÇ    - Fecha         ‚îÇ ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                    ‚îÇ              ‚îÇ
‚îÇ           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ           ‚îÇ  4. Postprocess    ‚îÇ ‚îÇ
‚îÇ           ‚îÇ    - Normalize     ‚îÇ ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   OUTPUT    ‚îÇ  JSON / CSV
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### C√≥digo de Ejemplo

```python
# Pipeline completo
from pathlib import Path
import sys
sys.path.insert(0, "src")

from io_pdf import pdf_to_text
from preprocess import clean_text
from sentence_split import split_sentences
from infer_classifier import SentenceTaskClassifier
from ner_extract import extract_person_responsable
from date_extract import extract_date_iso

# 1. Extracci√≥n (si es PDF)
text = pdf_to_text("documento.pdf")

# 2. Preprocesamiento
cleaned = clean_text(text)

# 3. Segmentaci√≥n
sentences = split_sentences(cleaned)

# 4. Clasificaci√≥n y extracci√≥n
clf = SentenceTaskClassifier(Path("models/best_baseline"))

for sent in sentences:
    is_task, score = clf.predict_sentence(sent)

    if is_task:
        responsable = extract_person_responsable(sent)
        fecha = extract_date_iso(sent, base_date="2025-11-09")

        print(f"TAREA: {sent}")
        print(f"  Responsable: {responsable}")
        print(f"  Fecha: {fecha}")
```

---

## Convenciones de Organizaci√≥n

### D√≥nde Poner Nuevos Archivos

#### C√≥digo de Producci√≥n
- **M√≥dulos core**: `src/nombre_modulo.py`
- **Experimentos**: `src/experiments/exp##_descripcion.py`
- **An√°lisis**: `src/analysis/nombre_analisis.py`
- **Mejoras LLM**: `src/llm_augmentation/nombre_mejora.py`
- **Scripts de datos**: `src/scripts/nombre_script.py`

#### Datos
- **Anotaciones**: `data/annotations/nombre_dataset.jsonl`
- **Splits**: `data/splits/{train,dev,test}.jsonl`
- **Scripts de datos**: `data/scripts/nombre_script.py`

#### Modelos
- **Modelo en producci√≥n**: `models/best_baseline/`
- **Experimentos**: `models/exp##_nombre/`

#### Documentaci√≥n
- **Docs principales**: `docs/NOMBRE_DOCUMENTO.md`
- **Docs antiguos**: `docs/archive/`
- **README t√©cnicos**: En la carpeta del m√≥dulo (ej: `src/llm_augmentation/README.md`)

#### Tests
- **Unit tests**: `tests/unit/test_nombre.py`
- **Integration tests**: `tests/integration/test_nombre.py`
- **Tests LLM-generados**: `tests/test_llm_generated.py`

#### Scripts de Utilidad
- **Scripts standalone**: `scripts/nombre_script.py`
- **Documentos de prueba**: `scripts/nombre_documento.txt`

### Nombres a Evitar

‚ùå **NO crear archivos con estos nombres**:
- `test.py`, `prueba.py`, `temp.py`, `tmp.py`
- `scratch.py`, `draft.py`, `borrador.py`
- `notas.md`, `resumen.md`, `anotaciones.md`
- `viejo_*.py`, `old_*.py`, `backup_*.py`

‚úÖ **S√ç usar nombres descriptivos**:
- `test_pipeline_complete.py` (si es un test formal)
- `analyze_model_errors.py` (an√°lisis espec√≠fico)
- `exp04_advanced_features.py` (experimento numerado)

### Convenci√≥n de Imports

```python
# Estructura recomendada de imports en archivos dentro de src/

# 1. Standard library
import json
import sys
from pathlib import Path
from typing import List, Dict

# 2. Third-party
import numpy as np
import pandas as pd
from sklearn.metrics import f1_score

# 3. Local (dentro de src/)
from preprocess import clean_text
from infer_classifier import SentenceTaskClassifier
```

### Convenci√≥n de Estructura de Archivos Python

```python
"""
Docstring del m√≥dulo: explicaci√≥n breve de qu√© hace
"""

# Imports

# Constantes globales (UPPER_CASE)
DEFAULT_THRESHOLD = 0.65

# Clases
class MiClase:
    pass

# Funciones
def mi_funcion():
    pass

# Main (si aplica)
if __name__ == "__main__":
    main()
```

---

## Cambios Realizados en esta Limpieza

### üì¶ Reorganizaci√≥n de Archivos

#### Movidos a `scripts/`
- ‚úÖ `test_pipeline.py` ‚Üí `scripts/test_pipeline.py`
- ‚úÖ `evaluate_model.py` ‚Üí `scripts/evaluate_model.py`
- ‚úÖ `test_document.txt` ‚Üí `scripts/test_document.txt`

**Raz√≥n**: Scripts de utilidad que no son parte del c√≥digo core de producci√≥n.

#### Movidos a `docs/`
- ‚úÖ `CLAUDE.md` ‚Üí `docs/CLAUDE.md`
- ‚úÖ `INSTRUCCIONES_USO.md` ‚Üí `docs/INSTRUCCIONES_USO.md`
- ‚úÖ `MEJORAS_SOBREAJUSTE.md` ‚Üí `docs/MEJORAS_SOBREAJUSTE.md`
- ‚úÖ `ESTRATEGIAS_LLM_IMPLEMENTADAS.md` ‚Üí `docs/ESTRATEGIAS_LLM_IMPLEMENTADAS.md`
- ‚úÖ `RESULTADOS_MEJORA.md` ‚Üí `docs/RESULTADOS_MEJORA.md`
- ‚úÖ `RESUMEN_MEJORAS_LLM.md` ‚Üí `docs/RESUMEN_MEJORAS_LLM.md`
- ‚úÖ `PROYECTO_COMPLETADO.md` ‚Üí `docs/PROYECTO_COMPLETADO.md`

**Raz√≥n**: Centralizar documentaci√≥n en carpeta dedicada.

#### Archivados en `docs/archive/`
- ‚úÖ `PROJECT.md` ‚Üí `docs/archive/PROJECT.md`
- ‚úÖ `RESUMEN_PROYECTO.md` ‚Üí `docs/archive/RESUMEN_PROYECTO.md`
- ‚úÖ `eval/reports.md` ‚Üí `docs/archive/reports.md`

**Raz√≥n**: Documentos antiguos o duplicados que no son necesarios en la ra√≠z.

### ‚öôÔ∏è Actualizaciones de C√≥digo

#### `scripts/test_pipeline.py`
- ‚úÖ Actualizado `sys.path.insert(0, ...)` de `parent` a `parent.parent`
- ‚úÖ Actualizado `base_dir` de `parent` a `parent.parent`

#### `scripts/evaluate_model.py`
- ‚úÖ Actualizado `sys.path.insert(0, ...)` de `parent` a `parent.parent`
- ‚úÖ Actualizado `base_dir` de `parent` a `parent.parent`

### üìÅ Nuevas Carpetas Creadas

- ‚úÖ `docs/` - Documentaci√≥n principal
- ‚úÖ `docs/archive/` - Documentaci√≥n antigua
- ‚úÖ `scripts/` - Scripts de utilidad
- ‚úÖ `scripts/archive/` - Scripts antiguos (vac√≠a por ahora)

### üóëÔ∏è Archivos Eliminados

**Ning√∫n archivo fue eliminado**. Todos los archivos fueron movidos a ubicaciones apropiadas para preservar el historial del proyecto.

### ‚úÖ Archivos Mantenidos en Ra√≠z

Los siguientes archivos permanecen en la ra√≠z por ser esenciales o convencionales:

- ‚úÖ `README.md` - Documentaci√≥n principal (convenci√≥n)
- ‚úÖ `ARCHITECTURE.md` - Este archivo (nuevo)
- ‚úÖ `requirements.txt` - Dependencias (convenci√≥n Python)
- ‚úÖ `run_app.sh` - Script de inicio r√°pido
- ‚úÖ `.gitignore` - Configuraci√≥n Git

---

## Verificaci√≥n de Funcionamiento

### Tests B√°sicos

```bash
# 1. Test del pipeline completo
python scripts/test_pipeline.py

# 2. Test de la app
streamlit run app/streamlit_app.py

# 3. Unit tests
pytest tests/ -v

# 4. Evaluaci√≥n en test set
python scripts/evaluate_model.py
```

### Comandos √ötiles

```bash
# Ver estructura del proyecto
tree -L 2 -I 'venv|__pycache__|.git|.pytest_cache|models/exp*'

# Correr evaluaci√≥n completa
python src/evaluate.py data/splits/test.jsonl models/best_baseline

# Generar nuevas variantes LLM (requiere API key)
export ANTHROPIC_API_KEY='tu-key'
python src/llm_augmentation/generate_difficult_data.py
```

---

## Dependencias del Proyecto

### Principales

```
sentence-transformers>=2.0.0    # Embeddings
scikit-learn>=1.0.0             # Clasificaci√≥n
transformers>=4.20.0            # NER
pdfplumber>=0.7.0               # PDF parsing
dateparser>=1.1.0               # Fecha parsing
streamlit>=1.20.0               # App web
```

### Opcionales

```
anthropic>=0.7.0                # Para mejoras LLM
pytest>=7.0.0                   # Para tests
```

Ver `requirements.txt` para lista completa.

---

## Pr√≥ximos Pasos Sugeridos

### Para Desarrollo

1. **Mejorar Extracci√≥n**:
   - Activar modo enhanced con LLM para casos dif√≠ciles
   - Fine-tune NER espec√≠fico para responsables
   - Mejorar parsing de fechas de proyecto

2. **Nuevos Experimentos**:
   - `exp02_bert_finetuning.py` ‚Üí F1 > 0.98
   - `exp03_ensemble.py` ‚Üí Combinar modelos
   - Data augmentation con back-translation

3. **Optimizaci√≥n**:
   - Quantization INT8 del modelo
   - ONNX export para inferencia r√°pida
   - Batch processing optimizado

### Para Documentaci√≥n

1. **Agregar**:
   - `docs/API.md` - Documentaci√≥n de API interna
   - `docs/DEPLOYMENT.md` - Gu√≠a de deployment
   - `docs/CONTRIBUTING.md` - Gu√≠a para contribuir

---

## Contacto y Mantenimiento

**Proyecto**: ActionMiner Lite
**Versi√≥n**: 1.0.0
**√öltima actualizaci√≥n**: 2025-11-09
**Mantenedor**: Deep Learning Team 2025

---

**Fin del documento ARCHITECTURE.md**
